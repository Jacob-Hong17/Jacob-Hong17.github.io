# jemdoc: menu{MENU}{index.html}, footer
==Bayesian Graph Convolution Network

Recently, Graph Convolutional Networks (GCNs) have been used to address node and graph classification and matrix completion. 
Brain disease prediction, which constructs the graph representation, also achieves effective results using the GCN. However, 
the current implementations have limited capability to incorporate uncertainty in the graph structure. Bayesian-GCN views the 
observed graph as a realization from a parametric family of random graphs. It targets inference of the joint posterior of the 
random graph parameters and the node (or graph) labels using Bayes' theorem.\n

\n
Compared to previous GCNs, the main difference is that when we do node label prediction, in our approach we simultaneously 
learn a graph generation model based on the observed underlying topology, and we learn the parameters of this graph generation 
model. We can sample a number of similar distributions but diverse topologies based on the posterior of the graph generation 
model. Thus, in the aggregation step of the GCNs, we are able to learn more general node embedding by incorporating information 
from different potential neighbors.\n

\n
For brain disease prediction, Resting-state functional magnetic resonance imaging (rs-fMRI) is transferred to Functional 
Connectivity (FC) using the Pearson correlation matrix and then vectorized for the subject feature vector. The phenotypic 
data (age, gender, gene expression, etc.) are normalized for similarity measures between subjects. The population graph from 
both brain imaging data and phenotypic data will feed into Bayesian GCN for prediction and uncertainty measure.\n

\n
Besides the graph-based rs-fMRI brain data, the Bayesian-GCN can apply to many other applications with graph representations, 
e.g., in biomedical area gene-gene or protein-protein interaction graphs, brain Region of Interest (ROI) connection graphs, 
and in traditional area citation networks, social dynamic road networks. For traditional image and text tasks that can 
construct graph representations, Bayesian-GCN also replies with a better uncertainty measure avoiding structure flaws.\n
~~~
{}{img_left}{project/gcn.png}{alt text}{426}{160}{} \n 
~~~







